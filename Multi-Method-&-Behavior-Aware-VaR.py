# -*- coding: utf-8 -*-
"""Another copy of RPM_Project_45.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vnSKQRMUAR-AzS-MD9-nkroNFCa6B8jz

#Research Project Title: Quantifying Investment Risk: A Multi-Method and Behavior-Aware VaR Framework for Personalized Portfolios

The project quantifies risk in a personal investment portfolio using diverse Value at Risk (VaR) methods:
- Historical Simulation
- Parametric VaR
- Monte Carlo Simulation
- Cornish-Fisher Expansion
- GARCH-based Volatility Modeling
- Machine Learning (Random Forest)

It segments portfolios by investor behavior (Conservative, Moderate, Aggressive) and evaluates model performance
via backtesting and scenario analysis.

## 1. Setting and Configuring the libraries
"""

!pip install yfinance
!pip install arch
!pip install plotly

# 1. Importing Required Libraries
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from arch import arch_model
from scipy.stats import norm
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from functools import lru_cache
import plotly.graph_objects as go

"""## 2. Portfolio Configurations and Introducing Risk Profiles"""

#  2. Portfolio Configuration
tickers = [
    'SPY',       # SPDR S&P 500 ETF - U.S. Large Cap Equities
    'AGG',       # iShares Core U.S. Aggregate Bond ETF - Broad Bond Exposure
    'QQQ',       # Invesco QQQ ETF - Nasdaq 100 (Tech-heavy Equities)
    'GLD',       # SPDR Gold Shares - Exposure to Gold (Commodities)
    'BTC-USD',   # Bitcoin (USD) - Leading Cryptocurrency
    'ETH-USD',   # Ethereum (USD) - Smart Contracts & Altcoins
    'IVV',       # iShares S&P 500 ETF - U.S. Large Cap Equities (BlackRock Portfolio)
    'IEFA',      # iShares MSCI EAFE ETF - International Equities (BlackRock Portfolio)
    'VTI',       # Vanguard Total Stock Market ETF (Vanguard Portfolio)
    'VXUS',      # Vanguard Total International Stock ETF (Vanguard Portfolio)
    'BND',       # Vanguard Total Bond Market ETF (Vanguard Portfolio)
    'VWOB'       # Vanguard Emerging Market Bond ETF (Vanguard Portfolio)
]

start_date = '2015-01-01'
end_date = '2024-12-31'
confidence_level = 0.95
rolling_window = 60  # Days for rolling VaR calculation

#  2.1 Behavioral Risk Profiles
risk_profiles = {
    "Conservative":    {'SPY': 0.2,  'AGG': 0.5, 'GLD': 0.2,  'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Moderate":        {'SPY': 0.4,  'AGG': 0.4, 'QQQ': 0.1,  'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Aggressive":      {'SPY': 0.25, 'QQQ': 0.25,'GLD': 0.1,  'BTC-USD': 0.2,  'ETH-USD': 0.2},
}
benchmark_profiles = {
    "BlackRock 60/40": {'IVV': 0.60, 'AGG': 0.30, 'IEFA': 0.10},
    "Vanguard VSMGX": {'VTI': 0.42, 'VXUS': 0.18, 'BND': 0.30, 'VWOB': 0.10}
}
all_profiles = {**risk_profiles, **benchmark_profiles}

"""This reflects user-specific portfolio behaviors â€” not just asset allocation but psychology and goals.

## 3. Downloading the data through Yfinance and Preprocessing it
"""

#  Data Fetching
def fetch_data(tickers, start, end):
    data = yf.download(tickers, start=start, end=end)['Close']
    return data.ffill().dropna()

price_data = fetch_data(tickers, start_date, end_date)
returns_data = price_data.pct_change().dropna()

"""## 4. Visualizing Risk Profiles"""

# Visualizing Risk Profiles
def visualize_allocations(profiles, cols=3):
    """Pie charts of asset allocations for each portfolio."""
    n = len(profiles)
    rows = int(np.ceil(n / cols))
    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*4))
    axs = axs.flatten()
    for ax, (name, weights) in zip(axs, profiles.items()):
        ax.pie(weights.values(), labels=weights.keys(), autopct='%1.0f%%', startangle=140)
        ax.set_title(name)
    for ax in axs[n:]:
        ax.axis('off')
    plt.suptitle("Asset Allocations: Behavioral & Benchmark Portfolios")
    plt.tight_layout()
    plt.show()

visualize_allocations(all_profiles)

"""## 5. Constructing Portfolio Return based on the weights"""

#  Portfolio Returns
def build_portfolio(weights, returns):
    weights = pd.Series(weights)
    common = returns.columns.intersection(weights.index)
    portfolio_returns = (returns[common] * weights[common]).sum(axis=1)  # Weighted sum of returns
    return portfolio_returns

"""## 6. VaR Methods â€” Traditional & Enhanced"""

#  VaR Calculation Methods
def historical_var(returns, alpha):
    return np.percentile(returns, 100 * (1 - alpha)) if len(returns) else np.nan

def parametric_var(returns, alpha):
    mu, sigma = returns.mean(), returns.std()
    return mu + sigma * norm.ppf(1 - alpha)

def monte_carlo_var(returns, alpha):
    mu, sigma = returns.mean(), returns.std()
    sims = np.random.normal(mu, sigma, 100000)
    return np.percentile(sims, 100 * (1 - alpha))

def cornish_fisher_var(returns, alpha):
    mu, sigma = returns.mean(), returns.std()
    skew, kurt = returns.skew(), returns.kurtosis()
    z = norm.ppf(1 - alpha)
    z_cf = z + (1/6)*(z**2 - 1)*skew + (1/24)*(z**3 - 3*z)*kurt - (1/36)*(2*z**3 - 5*z)*skew**2
    return mu + sigma * z_cf

@lru_cache(maxsize=None)
def garch_var_cached(returns_tuple, alpha):
    returns = pd.Series(list(returns_tuple))
    model = arch_model(returns * 100, vol='Garch', p=1, q=1)
    res = model.fit(disp='off')
    forecast = res.forecast(horizon=1)
    sigma = np.sqrt(forecast.variance.values[-1, :][0]) / 100
    return returns.mean() + sigma * norm.ppf(1 - alpha)

def expected_shortfall(returns, alpha):
    var = historical_var(returns, alpha)
    return returns[returns < var].mean()

"""## 7. Machine Learning-Based VaR (Random Forest)"""

def prepare_features(returns):
    df = pd.DataFrame({"returns": returns})
    df["lag1"] = df["returns"].shift(1)
    df["lag2"] = df["returns"].shift(2)
    df = df.dropna()
    X, y = df[["lag1", "lag2"]], df["returns"]
    return train_test_split(X, y, test_size=0.2, shuffle=False)

def ml_rf_var(returns, alpha):
    X_train, X_test, y_train, y_test = prepare_features(returns)
    model = RandomForestRegressor().fit(X_train, y_train)
    y_pred = model.predict(X_test)
    var_ml = np.percentile(y_pred, 100 * (1 - alpha))
    return -var_ml

"""## 8. Backtesting & Stress Testing"""

#  Backtesting
def backtest_var(returns, var_series):
    aligned_returns, aligned_var = returns.align(var_series, join='inner')
    breaches = aligned_returns < aligned_var
    return breaches,

# Stress Testing
def stress_var(weights_dict, period, alpha):
    tickers = list(weights_dict.keys())
    data = yf.download(tickers, start=period[0], end=period[1])['Close']
    data = data.dropna(axis=1, how='any')
    if data.empty:
        return np.nan
    available_assets = data.columns
    filtered_weights = {asset: weight for asset, weight in weights_dict.items() if asset in available_assets}
    total_weight = sum(filtered_weights.values())
    normalized_weights = {k: v / total_weight for k, v in filtered_weights.items()}
    returns = data.pct_change(fill_method=None).dropna()
    port_returns = build_portfolio(normalized_weights, returns)
    return historical_var(port_returns, alpha)

#  8. Backtesting
def backtest_var(returns, var_series):
    # Align the actual returns with the VaR predictions
    aligned_returns, aligned_var = returns.align(var_series, join='inner')
    # Identify when actual return is less than VaR estimate (breach)
    breaches = aligned_returns < -aligned_var  # Correct logic for breach
    # Return both breach points and average breach frequency (hit ratio)
    return breaches.sum(), breaches.mean()

# Run backtests for all portfolios
backtest_results = []
for name, weights in all_profiles.items():
    rets = build_portfolio(weights, returns_data)
    var_series = rets.rolling(rolling_window).apply(lambda x: historical_var(x, confidence_level))
    total_breaches, breach_rate = backtest_var(rets, var_series)
    backtest_results.append({
        "Portfolio": name,
        "Total Breaches": int(total_breaches),
        "Breach Rate": breach_rate
    })

backtest_df = pd.DataFrame(backtest_results).set_index("Portfolio")
print("\n VaR Backtest Results")
display(backtest_df.round(4))

import matplotlib.pyplot as plt
import numpy as np
df = backtest_df.copy()
df = df.sort_values(by="Total Breaches", ascending=False)
portfolios = df.index.tolist()
x = np.arange(len(portfolios))
# Normalizing breach rate to plot alongside breach counts
breaches = df["Total Breaches"]
breach_rate = df["Breach Rate"] * 100  # converting to percentage
width = 0.35
fig, ax = plt.subplots(figsize=(10, 6))
bar1 = ax.bar(x - width/2, breaches, width, label='Total Breaches', color='steelblue')
bar2 = ax.bar(x + width/2, breach_rate, width, label='Breach Rate (%)', color='orange')
ax.set_title("VaR Backtest Results")
ax.set_xlabel("Portfolio")
ax.set_ylabel("Count / %")
ax.set_xticks(x)
ax.set_xticklabels(portfolios)
ax.legend()
ax.bar_label(bar1, fmt='%d', padding=3, fontsize=9)
ax.bar_label(bar2, fmt='%.2f%%', padding=3, fontsize=9)
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()



import matplotlib.pyplot as plt

def plot_backtest_results(returns, var_series):
    breaches, _ = backtest_var(returns, var_series)
    plt.figure(figsize=(12, 5))
    plt.plot(returns.index, returns, label='Actual Returns', color='blue', alpha=0.6)
    plt.plot(var_series.index, var_series, label='VaR Threshold', color='red', linestyle='--')
    plt.fill_between(returns.index, returns, var_series,
                     where=breaches, facecolor='red', alpha=0.3, label='VaR Breaches')
    plt.title("Backtesting VaR: Actual Returns vs VaR")
    plt.legend()
    plt.xlabel("Date")
    plt.ylabel("Returns")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

def plot_stress_test(weights_dict, periods, alpha=0.05):
    stress_results = {}
    for name, period in periods.items():
        var = stress_var(weights_dict, period, alpha)
        stress_results[name] = var

    df = pd.DataFrame.from_dict(stress_results, orient='index', columns=['VaR'])

    plt.figure(figsize=(8, 5))
    sns.barplot(x=df.index, y='VaR', data=df, palette='coolwarm')
    plt.title("Stress Testing: VaR During Historical Crisis Periods")
    plt.ylabel("Value at Risk")
    plt.xlabel("Crisis Period")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# === 8. Backtesting ===
def backtest_var(returns, var_series):
    # Align the actual returns with the VaR predictions
    aligned_returns, aligned_var = returns.align(var_series, join='inner')
    # Identify when actual return is less than VaR estimate (breach)
    breaches = aligned_returns < aligned_var
    # Return both breach points and average breach frequency (hit ratio)
    return breaches, breaches.mean()

def plot_backtest_results(returns, var_series):
    # The error is here: backtest_var returns a tuple, not just the breaches array
    breaches, _ = backtest_var(returns, var_series) # This line now correctly unpacks the tuple
    plt.figure(figsize=(12, 5))
    plt.plot(returns.index, returns, label='Actual Returns', color='blue', alpha=0.6)
    plt.plot(var_series.index, var_series, label='VaR Threshold', color='red', linestyle='--')
    plt.fill_between(returns.index, returns, var_series,
                     where=breaches, facecolor='red', alpha=0.3, label='VaR Breaches')
    plt.title("Backtesting VaR: Actual Returns vs VaR")
    plt.legend()
    plt.xlabel("Date")
    plt.ylabel("Returns")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# For backtesting plot:
# Calculate predicted_var using one of the VaR methods for the desired portfolio.
# We are using historical VaR:
portfolio_returns = build_portfolio(risk_profiles['Moderate'], returns_data)  # Choose your portfolio and data
var_series = portfolio_returns.rolling(rolling_window).apply(lambda x: historical_var(x, confidence_level)) # Define var_series
plot_backtest_results(portfolio_returns, var_series)

# For stress test plot:
crisis_periods = {
    "COVID Crash": ("2020-02-01", "2020-04-30"),
    "2008 Crisis": ("2008-09-01", "2008-12-31"),
}
# Choose weights_dict based on your portfolio
weights_dict = risk_profiles['Moderate']  # Example using the Moderate risk profile
plot_stress_test(weights_dict, crisis_periods)

# === 9. Stress Testing ===
def stress_var(weights_dict, period, alpha):
    # Download price data
    tickers = list(weights_dict.keys())
    data = yf.download(tickers, start=period[0], end=period[1])['Close']

    # Drop assets with missing data
    data = data.dropna(axis=1, how='any')
    if data.empty:
        return np.nan

    # Normalize weights for available assets
    available_assets = data.columns
    filtered_weights = {asset: weight for asset, weight in weights_dict.items() if asset in available_assets}
    total_weight = sum(filtered_weights.values())
    normalized_weights = {k: v / total_weight for k, v in filtered_weights.items()}

    # Calculate portfolio returns
    returns = data.pct_change(fill_method=None).dropna()
    port_returns = build_portfolio(normalized_weights, returns)

    # Return historical VaR for the stress period
    return historical_var(port_returns, alpha)

import matplotlib.pyplot as plt

def plot_stress_test(weights_dict, crisis_periods, alpha=0.05):
    var_values = {}

    for name, period in crisis_periods.items():
        var = stress_var(weights_dict, period, alpha)
        var_values[name] = var

    plt.figure(figsize=(10, 6))
    bars = plt.bar(var_values.keys(), var_values.values(), color='salmon', edgecolor='black')

    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2.0, height, f"{height:.2%}",
                 ha='center', va='bottom' if height < 0 else 'top', fontsize=12)

    plt.title("Stress Testing Portfolio VaR during Crisis Periods", fontsize=14)
    plt.ylabel("Value at Risk (VaR)", fontsize=12)
    plt.axhline(0, color='black', linewidth=0.8)  # Baseline
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()
# For stress test plot:
crisis_periods = {
    "COVID Crash": ("2020-02-01", "2020-04-30"),
    "2008 Crisis": ("2008-09-01", "2008-12-31"),
}
# Choose weights_dict based on your portfolio
weights_dict = risk_profiles['Moderate']  # Example using the Moderate risk profile
plot_stress_test(weights_dict, crisis_periods)

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


risk_profiles = {
    "Conservative":    {'SPY': 0.2,  'AGG': 0.5, 'GLD': 0.2,  'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Moderate":        {'SPY': 0.4,  'AGG': 0.4, 'QQQ': 0.1,  'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Aggressive":      {'SPY': 0.25, 'QQQ': 0.25,'GLD': 0.1,  'BTC-USD': 0.2,  'ETH-USD': 0.2},
}

benchmark_profiles = {
    "BlackRock 60/40": {'IVV': 0.60, 'AGG': 0.30, 'IEFA': 0.10},
    "Vanguard VSMGX":  {'VTI': 0.42, 'VXUS': 0.18, 'BND': 0.30, 'VWOB': 0.10}
}

all_profiles = {**risk_profiles, **benchmark_profiles}


crisis_periods = {
    "COVID Crash": ("2020-02-01", "2020-04-30"),
    "2008 Crisis": ("2008-09-01", "2008-12-31"),
}


def build_portfolio(weights, returns_df):
    return returns_df[list(weights.keys())].mul(pd.Series(weights)).sum(axis=1)

def historical_var(returns, alpha=0.05):
    return returns.quantile(alpha)

def stress_var(weights_dict, period, alpha=0.05):
    tickers = list(weights_dict.keys())
    data = yf.download(tickers, start=period[0], end=period[1])['Close']

    data = data.dropna(axis=1, how='any')  # Remove columns with no data (e.g., ETH-USD in 2008)
    if data.empty:
        return np.nan

    available_assets = data.columns
    filtered_weights = {asset: weight for asset, weight in weights_dict.items() if asset in available_assets}
    total_weight = sum(filtered_weights.values())

    if total_weight == 0:
        return np.nan  # All assets missing in this time frame

    normalized_weights = {k: v / total_weight for k, v in filtered_weights.items()}
    returns = data.pct_change(fill_method=None).dropna()
    port_returns = build_portfolio(normalized_weights, returns)
    return historical_var(port_returns, alpha)
results = []
for profile_name, weights in all_profiles.items():
    for crisis, period in crisis_periods.items():
        var = stress_var(weights, period, alpha=0.05)
        results.append({"Profile": profile_name, "Crisis": crisis, "VaR": var})

df = pd.DataFrame(results)


plt.figure(figsize=(12, 6))
sns.set(style="whitegrid")
ax = sns.barplot(data=df, x="Crisis", y="VaR", hue="Profile", palette="tab10")


for container in ax.containers:
    ax.bar_label(container, fmt="%.4f", label_type="edge", padding=3, fontsize=8)

plt.title("Stress Testing VaR Across Profiles and Crisis Periods")
plt.ylabel("Value at Risk (VaR)")
plt.xlabel("Crisis Period")
plt.legend(title="Profile", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(True)
plt.show()

"""## 9. Running Simulations for All Risk Profiles"""

results = {}
final_returns = {}
port_returns_cache = {}
for name, weights in risk_profiles.items():
    port_returns = build_portfolio(weights, returns_data)
    port_returns_cache[name] = port_returns
    cum_returns = (1 + port_returns).cumprod() - 1
    final_returns[name] = cum_returns.iloc[-1]

    var_hist = historical_var(port_returns, confidence_level)
    var_param = parametric_var(port_returns, confidence_level)
    var_mc = monte_carlo_var(port_returns, confidence_level)
    var_garch = garch_var_cached(tuple(port_returns.values), confidence_level) # Changed garch_var to garch_var_cached
    var_cf = cornish_fisher_var(port_returns, confidence_level)
    var_rf = ml_rf_var(port_returns, confidence_level)
    es = expected_shortfall(port_returns, confidence_level)

    results[name] = {
        'Historical VaR': var_hist,
        'Parametric VaR': var_param,
        'Monte Carlo VaR': var_mc,
        'GARCH VaR': var_garch,
        'Cornish-Fisher VaR': var_cf,
        'ML VaR (RF)': var_rf,
        'Expected Shortfall': es
    }

    rolling_var = port_returns.rolling(rolling_window).apply(lambda x: historical_var(x, confidence_level))
    plt.figure(figsize=(10, 4))
    plt.plot(port_returns.index, port_returns, label='Returns', alpha=0.6)
    plt.plot(rolling_var.index, rolling_var, label='Rolling VaR', color='red')
    plt.title(f'{name} Portfolio - Rolling VaR')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    cum_returns.plot(title=f"{name} Portfolio - Cumulative Return", figsize=(10,4), grid=True)
    plt.ylabel("Cumulative Return")
    plt.tight_layout()
    plt.show()

"""## 10. Cumulative Return Plots"""

cumulative_net = {}
fig = go.Figure()

for name, returns in port_returns_cache.items():
    cum_returns = (1 + returns).cumprod()
    cumulative_net[name] = cum_returns
    fig.add_trace(go.Scatter(x=cum_returns.index, y=cum_returns, mode='lines', name=name, line=dict(width=2)))

fig.update_layout(
    title="Cumulative Return Comparison by Risk Profile (2015â€“2024)",
    xaxis_title="Date",
    yaxis_title="Cumulative Return ($)",
    template="plotly_white",
    hovermode="x unified",
    showlegend=True,
    plot_bgcolor="white",
    xaxis=dict(showgrid=True, gridcolor='LightGrey'),
    yaxis=dict(showgrid=True, gridcolor='LightGrey'),
)
fig.add_hline(y=1, line=dict(color='gray', dash='dash'))
fig.show()

cumulative_net = {}
plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")

for name, returns in port_returns_cache.items():
    cum_returns = (1 + returns).cumprod()
    cumulative_net[name] = cum_returns
    plt.plot(cum_returns.index, cum_returns, label=name, linewidth=2)

plt.title(" Cumulative Return Comparison by Risk Profile (2015â€“2024)", fontsize=14)
plt.ylabel("Cumulative Return ($)", fontsize=12)
plt.xlabel("Date", fontsize=12)
plt.legend(title="Risk Profile")
plt.grid(True, linestyle='--', alpha=0.5)
plt.axhline(1.0, color='gray', linestyle='--', linewidth=1)
plt.tight_layout()
plt.show()

"""## 11. Results Summary & Metrics"""

print("=== VaR Summary by Risk Profile ===")
print(pd.DataFrame(results).T.round(4))

print("\n=== Final Portfolio Values ===")
## Converting final returns to portfolio value assuming an initial investment of $1
final_summary = pd.DataFrame.from_dict(final_returns, orient='index', columns=['Final Value'])
## final value calculation assumes $1 starting value (no need to multiply by 100)
final_summary['Final Value'] = final_summary['Final Value'] * 1  # Assuming $1 starting value
print(final_summary.round(2))

#  CAGR, Volatility, Sharpe Ratio
print("\n=== Portfolio Performance Metrics ===")
risk_free_rate = 0.0

for name, series in cumulative_net.items():
    final_value = series.iloc[-1]  ## final portfolio value
    num_days = (series.index[-1] - series.index[0]).days  # total days in the period
    num_years = num_days / 365.25
    # Cumulative Annual Growth Rate (CAGR) calculation
    cagr = (final_value) ** (1 / num_years) - 1
    # Daily returns for portfolio to calculate volatility and Sharpe ratio
    returns = port_returns_cache[name]
    volatility = returns.std() * np.sqrt(252)  # Annualized volatility (252 trading days)
    # Sharpe ratio calculation
    sharpe = (returns.mean() * 252 - risk_free_rate) / volatility  # Assuming daily returns
    print(f"{name} Portfolio:")
    print(f" - Final Value: ${final_value:.2f}")
    print(f" - CAGR: {cagr:.2%}")
    print(f" - Volatility: {volatility:.2%}")
    print(f" - Sharpe Ratio: {sharpe:.2f}\n")

import matplotlib.pyplot as plt
import pandas as pd
var_data = {
    "Risk Profile": ["Conservative", "Moderate", "Aggressive"],
    "Historical VaR": [-0.0086, -0.0108, -0.0271],
    "Parametric VaR": [-0.0093, -0.0122, -0.0287],
    "Monte Carlo VaR": [-0.0092, -0.0122, -0.0288],
    "GARCH VaR": [-0.0081, -0.0105, -0.0237],
    "Cornish-Fisher VaR": [-0.0084, -0.0111, -0.0285],
    "ML VaR (RF)": [-0.0034, -0.0046, -0.0105],
}

df_var = pd.DataFrame(var_data).set_index("Risk Profile")
ax = df_var.plot(kind="bar", figsize=(12, 6),  width=0.8,title="VaR Comparison by Risk Profile")
for container in ax.containers:
    ax.bar_label(container, fmt='%.4f', label_type='edge', fontsize=8, padding=2)

plt.ylabel("VaR (Value at Risk)")
plt.grid(True)
plt.tight_layout()
plt.show()



"""## Risk-Return Tradeoff"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from arch import arch_model
from scipy.stats import norm
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from functools import lru_cache
import plotly.graph_objects as go

start_date = '2015-01-01'
end_date = '2024-12-31'
confidence_level = 0.95
rolling_window = 60  # days for rolling VaR

## Behavioral Risk Profiles
risk_profiles = {
    "Conservative": {'SPY': 0.2, 'AGG': 0.5, 'GLD': 0.2, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Moderate":     {'SPY': 0.4, 'AGG': 0.4, 'QQQ': 0.1, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Aggressive":   {'SPY': 0.25, 'QQQ': 0.25, 'GLD': 0.1, 'BTC-USD': 0.2, 'ETH-USD': 0.2},
}
# Institutional Benchmark Portfolios
benchmark_profiles = {
    "BlackRock 60/40": {'IVV': 0.60, 'AGG': 0.30, 'IEFA': 0.10},
    "Vanguard VSMGX":  {'VTI': 0.42, 'VXUS': 0.18, 'BND': 0.30, 'VWOB': 0.10},
}

all_tickers = sorted({t for w in all_profiles.values() for t in w})
price_data = yf.download(all_tickers, start=start_date, end=end_date)['Close'].dropna()
returns_data = price_data.pct_change().dropna()
def visualize_allocations(profiles, cols=3):
    """Pie charts of asset allocations for each portfolio."""
    n = len(profiles)
    rows = int(np.ceil(n / cols))
    fig, axs = plt.subplots(rows, cols, figsize=(cols*5, rows*4))
    axs = axs.flatten()
    for ax, (name, weights) in zip(axs, profiles.items()):
        ax.pie(weights.values(), labels=weights.keys(), autopct='%1.0f%%', startangle=140)
        ax.set_title(name)
    for ax in axs[n:]:
        ax.axis('off')
    plt.suptitle("Asset Allocations: Behavioral & Benchmark Portfolios")
    plt.tight_layout()
    plt.show()

def build_portfolio(weights, returns_df):
    """Calculate daily portfolio returns given weights."""
    w = pd.Series(weights)
    w /= w.sum()
    cols = w.index.intersection(returns_df.columns)
    return (returns_df[cols] * w[cols]).sum(axis=1)

def historical_var(returns, alpha=confidence_level):
    return -np.percentile(returns, (1 - alpha) * 100)

def parametric_var(returns, alpha=confidence_level):
    mu, sigma = returns.mean(), returns.std()
    return - (mu + sigma * norm.ppf(1 - alpha))

def monte_carlo_var(returns, alpha=confidence_level, sims=100000):
    mu, sigma = returns.mean(), returns.std()
    sims = np.random.normal(mu, sigma, sims)
    return -np.percentile(sims, (1 - alpha) * 100)

def cornish_fisher_var(returns, alpha=confidence_level):
    mu, sigma = returns.mean(), returns.std()
    skew, kurt = returns.skew(), returns.kurtosis()
    z = norm.ppf(1 - alpha)
    z_cf = z + (1/6)*(z**2 - 1)*skew + (1/24)*(z**3 - 3*z)*kurt - (1/36)*(2*z**3 - 5*z)*skew**2
    return - (mu + sigma * z_cf)

def expected_shortfall(returns, alpha=confidence_level):
    var = np.percentile(returns, (1 - alpha) * 100)
    return -returns[returns <= var].mean()

def prepare_features(returns):
    df = pd.DataFrame({"returns": returns})
    df["lag1"] = df["returns"].shift(1)
    df["lag2"] = df["returns"].shift(2)
    df = df.dropna()
    X, y = df[["lag1", "lag2"]], df["returns"]
    return train_test_split(X, y, test_size=0.2, shuffle=False)

def ml_rf_var(returns, alpha):
    X_train, X_test, y_train, y_test = prepare_features(returns)
    model = RandomForestRegressor().fit(X_train, y_train)
    y_pred = model.predict(X_test)
    var_ml = np.percentile(y_pred, 100 * (1 - alpha))
    return -var_ml

@lru_cache(maxsize=None)
def garch_var_cached(returns_tuple, alpha=confidence_level):
    series = pd.Series(list(returns_tuple))
    model = arch_model(series * 100, vol='Garch', p=1, q=1)
    res = model.fit(disp='off')
    sigma = np.sqrt(res.forecast(horizon=1).variance.values[-1, :][0]) / 100
    mu = series.mean()
    return - (mu + sigma * norm.ppf(1 - alpha))

def backtest_var(returns, var_series):
    aligned_ret, aligned_var = returns.align(var_series, join='inner')
    breaches = aligned_ret < -aligned_var
    return breaches.sum(), breaches.mean()

def calculate_sharpe_ratio(returns, risk_free_rate=0):
    # Annualized Return
    annualized_return = returns.mean() * 252
    # Annualized Volatility
    annualized_volatility = returns.std() * np.sqrt(252)
    # Sharpe Ratio (assuming risk-free rate is zero)
    sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility
    return sharpe_ratio

results = []
portfolio_returns = {}
for name, weights in all_profiles.items():
    rets = build_portfolio(weights, returns_data)
    portfolio_returns[name] = rets
    mu = rets.mean() * 252
    sigma = rets.std() * np.sqrt(252)
    hist = historical_var(rets)
    param = parametric_var(rets)
    mc = monte_carlo_var(rets)
    cf = cornish_fisher_var(rets)
    ml_rf = ml_rf_var(rets, confidence_level)
    es = expected_shortfall(rets)
    garch = garch_var_cached(tuple(rets.values))
    roll_var = rets.rolling(rolling_window).apply(
        lambda x: -np.percentile(x, (1 - confidence_level)*100)
    )
    breaches, breach_rate = backtest_var(rets, roll_var)
    sharpe_ratio = calculate_sharpe_ratio(rets)

    results.append({
        'Portfolio': name,
        'Ann Return': mu,
        'Ann Vol': sigma,
        'VaR 95%': hist,
        'Param VaR': param,
        'MC VaR': mc,
        'CF VaR': cf,
        'ML VaR': ml_rf,
        'GARCH VaR': garch,
        'ES': es,
        'Breaches': breaches,
        'Breach Rate': breach_rate,
        'Sharpe Ratio': sharpe_ratio
    })

summary_df = pd.DataFrame(results).set_index('Portfolio').round(4)
print(" Portfolio Risk & Performance Summary")
display(summary_df)

#  6. Results
plt.figure(figsize=(10,6))
sns.scatterplot(
    data=summary_df.reset_index(),
    x='Ann Vol', y='Ann Return', hue='Portfolio', size='Ann Return', sizes=(100,400)
)
for idx, row in summary_df.iterrows():
    plt.text(row['Ann Vol']*1.01, row['Ann Return']*1.01, idx)
plt.title('Risk vs Return: All Portfolios')
plt.xlabel('Annualized Volatility')
plt.ylabel('Annualized Return')
plt.grid(True)
plt.tight_layout()
plt.show()

def calculate_sharpe_ratio(returns, risk_free_rate=0):
    # Annualized Return
    annualized_return = returns.mean() * 252
    # Annualized Volatility
    annualized_volatility = returns.std() * np.sqrt(252)
    # Sharpe Ratio
    sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility
    return sharpe_ratio

sharpe_ratios = {}

for portfolio_name, portfolio_returns_data in portfolio_returns.items():
    sharpe_ratios[portfolio_name] = calculate_sharpe_ratio(portfolio_returns_data)

print("Sharpe Ratios for each portfolio:")
for portfolio_name, sharpe_ratio in sharpe_ratios.items():
    print(f"{portfolio_name}: {sharpe_ratio:.4f}")





!pip install qpsolvers

print("=== VaR Summary by Risk Profile ===")
print(pd.DataFrame(results).T.round(4))  # VaR results
#Portfolio Performance Metrics ===
print("\n=== Portfolio Performance Metrics ===")

# Define risk-free rate
risk_free_rate = 0.0
performance_summary = pd.DataFrame(columns=['Final Value', 'CAGR', 'Volatility', 'Sharpe Ratio'])
for name, series in cumulative_net.items():
    final_value = series.iloc[-1]
    start_date = series.index[0]
    end_date = series.index[-1]
    num_days = (end_date - start_date).days
    num_years = num_days / 365.25  # Leap years considered

    # CAGR
    cagr = (final_value / initial_investment) ** (1 / num_years) - 1

    # Volatility from daily returns
    returns = port_returns_cache[name]
    volatility = returns.std() * np.sqrt(252)  # Annualized

    # Sharpe ratio
    sharpe = (returns.mean() * 252 - risk_free_rate) / volatility

    # Saving to summary table
    performance_summary.loc[name] = [final_value, cagr, volatility, sharpe]
    print(f"{name} Portfolio:")
    print(f" - Final Value: ${final_value:.2f}")
    print(f" - CAGR: {cagr:.2%}")
    print(f" - Volatility: {volatility:.2%}")
    print(f" - Sharpe Ratio: {sharpe:.2f}\n")

print("ðŸ“Š Summary Table: CAGR, Volatility, Sharpe Ratio\n")
display(performance_summary.round(4).style.format({
    "Final Value": "${:.2f}",
    "CAGR": "{:.2%}",
    "Volatility": "{:.2%}",
    "Sharpe Ratio": "{:.2f}"
}).set_caption("Risk-Return Summary: Personal vs Institutional Portfolios"))



import pandas as pd
import numpy as np

risk_free_rate = 0.0
initial_investment = 1
final_summary = {}
performance_summary = pd.DataFrame(
    columns=['Final Value', 'CAGR', 'Volatility', 'Sharpe Ratio']
)

# Calculating metrics for each portfolio
for name, series in cumulative_net.items():
    final_value = series.iloc[-1]
    start_date = series.index[0]
    end_date = series.index[-1]
    num_days = (end_date - start_date).days
    num_years = num_days / 365.25

    # CAGR (compounded annual growth rate)
    cagr = (final_value / initial_investment) ** (1 / num_years) - 1

    # Annualized volatility
    returns = port_returns_cache[name]
    volatility = returns.std() * np.sqrt(252)

    # Sharpe Ratio (annualized)
    sharpe = (returns.mean() * 252 - risk_free_rate) / volatility

    final_summary[name] = final_value
    performance_summary.loc[name] = [
        final_value, cagr, volatility, sharpe
    ]

# Final Portfolio Values
print("\n=== Final Portfolio Values (Aligned Period, Compounded) ===")
final_value_df = pd.DataFrame.from_dict(
    final_summary, orient='index', columns=['Final Value']
)
print(final_value_df.round(2))

# Portfolio Performance Metrics
print("\n=== Portfolio Performance Metrics (Aligned, Compounded, Sharpe uses 0.0% RF) ===")
print(performance_summary.round(4).to_string())

try:
    display(
        performance_summary.round(4).style.format({
            "Final Value": "${:.2f}",
            "CAGR": "{:.2%}",
            "Volatility": "{:.2%}",
            "Sharpe Ratio": "{:.2f}"
        }).set_caption("Risk-Return Summary: Aligned Portfolios")
    )
except NameError:
    pass  # display() only works in Jupyter/IPython

"""## Behavior-Aware Regime-Switching Portfolio Simulator

Rather than assuming fixed investor profiles (aggressive, moderate, conservative), we propose a **dynamic behavioral switching model** based on market regimes.

- During **bull markets**, investors tend to become more risk-tolerant, shifting toward aggressive allocations.
- During **bear markets**, risk aversion dominates, favoring conservative behaviors.
- Market regimes are determined using **rolling returns** to detect trends.

This approach adds realism to portfolio simulation and better captures human behavior in financial decision-making.

**1. Regime-Switching Portfolios**

**Objective:** Dynamically adjust portfolio exposure based on market conditions.

Detects market regimes (Bull/Bear) using SPYâ€™s 1-year rolling return.

*   Detects market regimes (Bull/Bear) using SPYâ€™s 1-year rolling return.
*   Applies a momentum filter to refine entry signals.
* Executes trades only during Bull + Positive Momentum regimes.
* Evaluates Conservative, Moderate, and Aggressive portfolios under this regime-switching logic.
* Outputs strategy performance (Sharpe, CAGR, trade count, cumulative return).
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 1. Downloading Data & Utilities
def download_data(tickers, start_date, end_date):
    price_data = yf.download(tickers, start=start_date, end=end_date)['Close']
    return price_data.dropna()

def calculate_returns(price_data):
    return np.log(price_data / price_data.shift(1)).dropna()

def compute_portfolio_returns(weights, returns):
    aligned_returns = returns[list(weights.keys())]
    weight_vector = np.array(list(weights.values()))
    return aligned_returns.dot(weight_vector)

# 2. Behavior-Weighted VaR

def compute_behavior_weighted_var(portfolio_returns, behavior_score, confidence_level=0.95):
    base_var = -np.percentile(portfolio_returns, 100 * (1 - confidence_level))
    adjusted_var = base_var * (1 + behavior_score)
    return adjusted_var

# 3. Behavioral Stress Testing

def simulate_behavioral_stress(portfolio_returns, profile_type):
    shocked = portfolio_returns.copy()
    mask = shocked < -0.01
    if profile_type == "Conservative":
        shocked[mask] *= 1.5  # Panic selling worsens drawdown
    elif profile_type == "Aggressive":
        shocked[mask] *= 0.5  # Buy-the-dip cushions losses
    return shocked


# 4. Regime + Momentum Strategy

def detect_market_regime(price_data, window=252):
    spy_returns = price_data['SPY'].pct_change(periods=window)
    return (spy_returns > 0).astype(int).rename('Regime')  # Bull = 1

def momentum_signal(returns, window=252):
    momentum = returns.rolling(window=window).mean().mean(axis=1)
    return (momentum > 0).astype(int).rename('Momentum')

def generate_trade_signal(regime, momentum):
    signal = (regime & momentum).astype(int).rename('Signal')
    signal_shifted = signal.shift(1, fill_value=0)
    return signal_shifted, signal_shifted.diff().abs().fillna(0)

def simulate_strategy(portfolio_returns, signal, transaction_cost=0.0015, turnover=0.3):
    raw_returns = portfolio_returns * signal
    trades = signal.diff().abs().fillna(0)
    cost = trades * transaction_cost * turnover
    net_returns = raw_returns - cost
    return net_returns, trades

def summarize_strategy(net_returns, trades, label='Strategy'):
    cumulative = (1 + net_returns).cumprod()
    print(f"\nðŸ”¹ {label}")
    print(f"Total Trades: {int(trades.sum())}")
    print(f"Cumulative Return: {cumulative.iloc[-1]:.2f}")
    print(f"Annualized Return: {net_returns.mean() * 252:.2%}")
    print(f"Sharpe Ratio: {net_returns.mean() / net_returns.std() * np.sqrt(252):.2f}")
    cumulative.plot(title=f"{label} Net Value")

"""**2. Behavior-Weighted VaR**

**Objective:** Personalize Value at Risk (VaR) based on behavioral tendencies.
Assigninga a continuous behavior score to each investor type.
Computes personalized VaR using:

VaR_behavior = VaR x (1+ behavior_score)
"""

# 2. Behavior-Weighted VaR
def compute_behavior_weighted_var(portfolio_returns, behavior_score, confidence_level=0.95):
    base_var = -np.percentile(portfolio_returns, 100 * (1 - confidence_level))
    adjusted_var = base_var * (1 + behavior_score)
    return adjusted_var

"""**3. Stress Test with Behavioral Reactions**

**Objective:** Simulate psychological responses to crisis scenarios.

* Models investor behavior during large drawdowns:
* Aggressive: Buys the dip â†’ softened losses.
* Conservative: Panic sells â†’ amplified losses.
* Adjusts return series accordingly to visualize behavioral stress resilience.
* Plots stress-adjusted portfolio outcomes for each profile.
"""

# 3. Behavioral Stress Testing
def simulate_behavioral_stress(portfolio_returns, profile_type):
    shocked = portfolio_returns.copy()
    mask = shocked < -0.01
    if profile_type == "Conservative":
        shocked[mask] *= 1.5  # Panic selling worsens drawdown
    elif profile_type == "Aggressive":
        shocked[mask] *= 0.5  # Buy-the-dip cushions losses
    return shocked

def compute_behavior_weighted_var(aggressive_var, conservative_var, moderate_var, behavior_score):
    return (aggressive_var * behavior_score) + (moderate_var * (0.5 - abs(behavior_score - 0.5))) + (conservative_var * (1 - behavior_score))

def simulate_behavioral_stress(portfolio_value, behavior_type='aggressive', drawdown=0.3):
    if behavior_type == 'aggressive':
        return portfolio_value * (1 - drawdown) * 1.05  # Buy-the-dip recovery
    elif behavior_type == 'conservative':
        return portfolio_value * (1 - drawdown) * 0.95  # Panic selling
    elif behavior_type == 'moderate':
        return portfolio_value * (1 - drawdown) * 1.00  # Balanced reaction
    return portfolio_value * (1 - drawdown)  # No action


def download_data(tickers, start_date, end_date):
    price_data = yf.download(tickers, start=start_date, end=end_date)['Close']
    return price_data.dropna()

def run_full_analysis(tickers, risk_profiles, start_date, end_date):
    print("Downloading data...")
    price_data = download_data(tickers, start_date, end_date)
    returns = calculate_returns(price_data)

    print("Detecting market regime and momentum...")
    regime = detect_market_regime(price_data)
    momentum = momentum_signal(returns)
    signal, trades = generate_trade_signal(regime, momentum)

    behavior_scores = {'Conservative': 0.2, 'Moderate': 0.0, 'Aggressive': -0.2}

    for profile, weights in risk_profiles.items():
        print(f"\n=======================")
        print(f"{profile} Portfolio Analysis")
        print(f"=======================")
        portfolio_returns = compute_portfolio_returns(weights, returns)

        # Regime-switching strategy
        net_returns, trade_flags = simulate_strategy(portfolio_returns, signal)
        summarize_strategy(net_returns, trade_flags, label=f"{profile} Regime Strategy")

        # Behavior-weighted VaR
        score = behavior_scores.get(profile, 0.0)
        var = compute_behavior_weighted_var(0.1, 0.2, 0.15, score)  # Example VaR values for Aggressive, Conservative, and Moderate
        print(f"Behavior-Weighted VaR (95%) for {profile}: {var:.4f}")

        # Behavioral Stress Test
        stressed = simulate_behavioral_stress(portfolio_returns, profile)
        stress_cumulative = (1 + stressed).cumprod()
        plt.figure()
        stress_cumulative.plot(title=f"{profile} Behavioral Stress Test")
        plt.show()

risk_profiles = {
    "Conservative": {'SPY': 0.2, 'AGG': 0.5, 'GLD': 0.2, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Moderate": {'SPY': 0.4, 'AGG': 0.4, 'QQQ': 0.1, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Aggressive": {'SPY': 0.25, 'QQQ': 0.25, 'GLD': 0.1, 'BTC-USD': 0.2, 'ETH-USD': 0.2}
}

run_full_analysis(
    tickers=['SPY', 'AGG', 'QQQ', 'GLD', 'BTC-USD', 'ETH-USD'],
    risk_profiles=risk_profiles,
    start_date='2015-01-01',
    end_date='2024-12-31'
)

risk_profiles = {
    "Conservative": {'SPY': 0.2, 'AGG': 0.5, 'GLD': 0.2, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Moderate":     {'SPY': 0.4, 'AGG': 0.4, 'QQQ': 0.1, 'BTC-USD': 0.05, 'ETH-USD': 0.05},
    "Aggressive":   {'SPY': 0.25, 'QQQ': 0.25, 'GLD': 0.1, 'BTC-USD': 0.2, 'ETH-USD': 0.2}
}


def download_data(tickers, start_date, end_date):
    data = yf.download(tickers, start=start_date, end=end_date)['Close']
    return data.dropna()
def calculate_returns(price_data):
    return np.log(price_data / price_data.shift(1)).dropna()
def compute_portfolio_returns(weights, returns):
    aligned = returns[list(weights.keys())]
    return aligned.dot(np.array(list(weights.values())))
def compute_behavior_weighted_var(portfolio_returns, behavior_score, confidence_level=0.95):
    var = -np.percentile(portfolio_returns, 100 * (1 - confidence_level))
    return var * (1 + behavior_score)

def simulate_behavioral_stress(portfolio_value, behavior_type='aggressive', drawdown=0.3):
    if behavior_type == 'aggressive':
        return portfolio_value * (1 - drawdown) * 1.05  # Buy-the-dip recovery
    elif behavior_type == 'conservative':
        return portfolio_value * (1 - drawdown) * 0.95  # Panic selling
    elif behavior_type == 'moderate':
        return portfolio_value * (1 - drawdown) * 1.00  # Balanced reaction
    return portfolio_value * (1 - drawdown)  # No action

def detect_market_regime(price_data, window=252):
    returns = price_data['SPY'].pct_change(periods=window)
    return (returns > 0).astype(int).rename('Regime')


def momentum_signal(returns, window=252):
    momentum = returns.rolling(window).mean().mean(axis=1)
    return (momentum > 0).astype(int).rename('Momentum')

# Combining regime + momentum into signal
def generate_trade_signal(regime, momentum):
    signal = (regime & momentum).astype(int).rename('Signal')
    return signal.shift(1, fill_value=0), signal.diff().abs().fillna(0)

# Simulating strategy returns with transaction costs
def simulate_strategy(portfolio_returns, signal, transaction_cost=0.0015, turnover=0.3):
    raw = portfolio_returns * signal
    trades = signal.diff().abs().fillna(0)
    costs = trades * transaction_cost * turnover
    return raw - costs, trades


def summarize_strategy(net_returns, trades, label='Strategy'):
    cumulative = 100 * (1 + net_returns).cumprod()
    print(f"\n {label}")
    print(f"Total Trades: {int(trades.sum())}")
    print(f"Cumulative Return: {cumulative.iloc[-1]:.2f}")
    print(f"Annualized Return: {net_returns.mean() * 252:.2%}")
    print(f"Sharpe Ratio: {net_returns.mean() / net_returns.std() * np.sqrt(252):.2f}")
    cumulative.plot(title=f"{label} Net Value")


def run_full_analysis(tickers, risk_profiles, start_date, end_date):
    print("Downloading data...")
    price_data = download_data(tickers, start_date, end_date)
    returns = calculate_returns(price_data)

    print("Detecting market regime and momentum...")
    regime = detect_market_regime(price_data)
    momentum = momentum_signal(returns)
    signal, trades = generate_trade_signal(regime, momentum)

    behavior_scores = {'Conservative': 0.2, 'Moderate': 0.0, 'Aggressive': -0.2}

    for profile, weights in risk_profiles.items():
        print(f"\n=======================")
        print(f"{profile} Portfolio Analysis")
        print(f"=======================")

        # Portfolio returns
        portfolio_returns = compute_portfolio_returns(weights, returns)

        # Strategy simulation
        net_returns, trade_flags = simulate_strategy(portfolio_returns, signal)
        summarize_strategy(net_returns, trade_flags, label=f"{profile} Regime Strategy")

        # Behavior-weighted VaR
        score = behavior_scores.get(profile, 0.0)
        var = compute_behavior_weighted_var(portfolio_returns, score)
        print(f"Behavior-Weighted VaR (95%) for {profile}: {var:.4f}")

        # Behavioral Stress Test
        stressed = simulate_behavioral_stress(portfolio_returns, profile)
        stress_cumulative = 100 * (1 + stressed).cumprod()

        # Plotting with regime background
        plt.figure(figsize=(14, 7))
        ax = plt.gca()

        ax.fill_between(price_data.index, 0, 1, where=(regime == 1), color="green", alpha=0.2, label="Bull Market", transform=ax.get_xaxis_transform())
        ax.fill_between(price_data.index, 0, 1, where=(regime == 0), color="red", alpha=0.2, label="Bear Market", transform=ax.get_xaxis_transform())

        stress_cumulative.plot(ax=ax, label=f"{profile} Stress Test", color="blue")

        plt.title(f"{profile} Behavioral Stress Test with Market Regime Shading")
        plt.xlabel("Date")
        plt.ylabel("Portfolio Value ")
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()

# Run the analysis
run_full_analysis(
    tickers=['SPY', 'AGG', 'QQQ', 'GLD', 'BTC-USD', 'ETH-USD'],
    risk_profiles=risk_profiles,
    start_date='2015-01-01',
    end_date='2024-12-31'
)

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import yfinance as yf

# Step 1: Defining benchmark ETF weights
benchmark_profiles = {
    "BlackRock 60/40": {'IVV': 0.60, 'AGG': 0.30, 'IEFA': 0.10},
    "Vanguard VSMGX": {'VTI': 0.42, 'VXUS': 0.18, 'BND': 0.30, 'VWOB': 0.10}
}

all_etfs = list(set(etf for profile in benchmark_profiles.values() for etf in profile))
etf_data = yf.download(all_etfs, start="2015-01-01", end="2024-12-31")['Close'].dropna()
etf_returns = etf_data.pct_change().dropna()

# Step 2: Calculating benchmark return series
benchmark_returns_cache = {}
for benchmark_name, allocations in benchmark_profiles.items():
    weighted_returns = sum(
        weight * etf_returns[etf] for etf, weight in allocations.items()
    )
    benchmark_returns_cache[benchmark_name] = weighted_returns

# Step 3: Defining portfolio types
portfolio_types = {
    "Conservative": "Portfolio",
    "Moderate": "Portfolio",
    "Aggressive": "Portfolio",
    "BlackRock 60/40": "Benchmark",
    "Vanguard VSMGX": "Benchmark"
}


risk_free_rate = 0.0
initial_investment = 1

# Combining custom + benchmark returns into one dictionary
all_returns_cache = {}
all_returns_cache.update(benchmark_returns_cache)
all_returns_cache.update(port_returns_cache)  # Your custom portfolios must already be populated

# Step 4: Calculaing cumulative returns and metrics
cumulative_all = {}
performance_summary = pd.DataFrame(columns=['Type', 'Final Value', 'CAGR', 'Volatility', 'Sharpe Ratio'])

for name, returns in all_returns_cache.items():
    cum_returns = (1 + returns).cumprod()
    cumulative_all[name] = cum_returns

    final_value = cum_returns.iloc[-1]
    num_years = (cum_returns.index[-1] - cum_returns.index[0]).days / 365.25
    cagr = (final_value / initial_investment) ** (1 / num_years) - 1
    volatility = returns.std() * np.sqrt(252)
    sharpe = (returns.mean() * 252 - risk_free_rate) / volatility

    performance_summary.loc[name] = [
        portfolio_types.get(name, "Portfolio"), final_value, cagr, volatility, sharpe
    ]

# Step 5: Print summaries
print("\n=== Final Portfolio Values ===")
print(performance_summary[['Final Value']].round(2))

print("\n=== Portfolio Performance Metrics (CAGR, Volatility, Sharpe) ===")
performance_summary = performance_summary.sort_values(['Type', 'Sharpe Ratio'], ascending=[True, False])
print(performance_summary.round(4).to_string())

# Step 6: Plotting Cumulative Returns (All Portfolios + Benchmarks)
fig = go.Figure()

for name, cum_returns in cumulative_all.items():
    fig.add_trace(go.Scatter(
        x=cum_returns.index,
        y=cum_returns,
        mode='lines',
        name=name,
        line=dict(width=2)
    ))

fig.update_layout(
    title="Cumulative Return Comparison: Portfolios vs Benchmarks (2015â€“2024)",
    xaxis_title="Date",
    yaxis_title="Cumulative Return ($)",
    template="plotly_white",
    hovermode="x unified",
    showlegend=True,
    plot_bgcolor="white",
    xaxis=dict(showgrid=True, gridcolor='LightGrey'),
    yaxis=dict(showgrid=True, gridcolor='LightGrey'),
)
fig.add_hline(y=1, line=dict(color='gray', dash='dash'))
fig.show()

try:
    display(
        performance_summary.round(4).style.format({
            "Final Value": "${:.2f}",
            "CAGR": "{:.2%}",
            "Volatility": "{:.2%}",
            "Sharpe Ratio": "{:.2f}"
        }).set_caption(" Risk-Return Summary: Custom vs Institutional Portfolios")
    )
except NameError:
    pass

import pandas as pd
import plotly.express as px
data = {
    "Portfolio": [
        "BlackRock 60/40", "Vanguard VSMGX",  # Benchmarks
        "Conservative", "Moderate", "Aggressive"  # Portfolios
    ],
    "Type": [
        "Benchmark", "Benchmark",
        "Portfolio", "Portfolio", "Portfolio"
    ],
    "Final Value": [
        2.38, 2.01,
        2.30, 2.73, 8.71
    ],
    "CAGR": [
        0.0905, 0.0722,
        0.1238, 0.1510, 0.3543
    ],
    "Volatility": [
        0.1246, 0.1133,
        0.0928, 0.1214, 0.2867
    ],
    "Sharpe Ratio": [
        0.76, 0.67,
        0.91, 0.86, 0.87
    ]
}

df = pd.DataFrame(data)
import plotly.express as px
melted = pd.melt(
    df,
    id_vars=["Portfolio", "Type"],
    value_vars=["Sharpe Ratio", "CAGR", "Volatility"],
    var_name="Metric",
    value_name="Value"
)

fig = px.bar(
    melted,
    x="Portfolio",
    y="Value",
    color="Type",
    facet_col="Metric",
    barmode="group",
    text_auto=".2f",
    title=" Performance Metrics: Portfolios vs Benchmarks",
    template="plotly_white"
)
fig.update_yaxes(matches=None, showgrid=True, gridcolor='lightgray')
fig.update_layout(
    height=500,
    showlegend=True
)
fig.show()